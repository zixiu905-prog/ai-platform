import React, { useState, useRef, useEffect, useCallback } from 'react';
import { useDesktopTheme } from '../../contexts/DesktopThemeContext';

interface VoiceRecorderProps {
  onRecordingStart?: () => void;
  onRecordingStop?: (audioBlob: Blob) => void;
  onTranscriptionComplete?: (text: string, confidence: number) => void;
  onError?: (error: string) => void;
  maxDuration?: number; // æœ€å¤§å½•åˆ¶æ—¶é•¿ï¼ˆç§’ï¼‰
  className?: string;
}

interface RecordingState {
  isRecording: boolean;
  isPaused: boolean;
  duration: number;
  audioLevel: number;
}

interface VoiceSettings {
  language: string;
  model: string;
  autoSubmit: boolean;
  confidenceThreshold: number;
}

export const VoiceRecorder: React.FC<VoiceRecorderProps> = ({
  onRecordingStart,
  onRecordingStop,
  onTranscriptionComplete,
  onError,
  maxDuration = 300,
  className = ''
}) => {
  const { theme } = useDesktopTheme();
  
  // å½•åˆ¶çŠ¶æ€
  const [recordingState, setRecordingState] = useState<RecordingState>({
    isRecording: false,
    isPaused: false,
    duration: 0,
    audioLevel: 0
  });
  
  // è¯­éŸ³è®¾ç½®
  const [voiceSettings, setVoiceSettings] = useState<VoiceSettings>({
    language: 'zh-CN',
    model: 'whisper-1',
    autoSubmit: false,
    confidenceThreshold: 0.7
  });
  
  // ä¸Šä¼ çŠ¶æ€
  const [isUploading, setIsUploading] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  
  // å½•åˆ¶ç›¸å…³å¼•ç”¨
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const animationRef = useRef<number | null>(null);

  // è·å–è¯­éŸ³è®¾ç½®
  useEffect(() => {
    loadVoiceSettings();
  }, []);

  // æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      stopRecording();
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, []);

  const loadVoiceSettings = async () => {
    try {
      const response = await fetch('/api/voice/settings', {
        credentials: 'include'
      });
      const result = await response.json();
      if (result.success) {
        setVoiceSettings(result.data);
      }
    } catch (error) {
      console.error('åŠ è½½è¯­éŸ³è®¾ç½®å¤±è´¥:', error);
    }
  };

  // å¼€å§‹å½•åˆ¶
  const startRecording = async () => {
    try {
      // è¯·æ±‚éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        }
      });

      audioStreamRef.current = stream;

      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡å’Œåˆ†æå™¨
      audioContextRef.current = new AudioContext();
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 256;

      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);

      // åˆ›å»ºMediaRecorder
      const options = {
        mimeType: getSupportedMimeType(),
        audioBitsPerSecond: 128000
      };

      const mediaRecorder = new MediaRecorder(stream, options);
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = handleRecordingStop;

      // å¼€å§‹å½•åˆ¶
      mediaRecorder.start(100); // æ¯100msæ”¶é›†ä¸€æ¬¡æ•°æ®
      
      // å¼€å§‹è®¡æ—¶
      timerRef.current = setInterval(() => {
        setRecordingState(prev => {
          const newDuration = prev.duration + 1;
          if (newDuration >= maxDuration) {
            stopRecording();
          }
          return { ...prev, duration: newDuration };
        });
      }, 1000);

      // å¼€å§‹éŸ³é¢‘çº§åˆ«ç›‘æµ‹
      startAudioLevelMonitoring();

      setRecordingState(prev => ({
        ...prev,
        isRecording: true,
        duration: 0,
        audioLevel: 0
      }));

      onRecordingStart?.();
      
      console.log('å½•åˆ¶å¼€å§‹');
    } catch (error) {
      console.error('å½•åˆ¶å¯åŠ¨å¤±è´¥:', error);
      onError?.('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
    }
  };

  // åœæ­¢å½•åˆ¶
  const stopRecording = () => {
    if (mediaRecorderRef.current && recordingState.isRecording) {
      mediaRecorderRef.current.stop();
      
      // åœæ­¢éŸ³é¢‘æµ
      if (audioStreamRef.current) {
        audioStreamRef.current.getTracks().forEach(track => track.stop());
        audioStreamRef.current = null;
      }
      
      // æ¸…ç†éŸ³é¢‘ä¸Šä¸‹æ–‡
      if (audioContextRef.current) {
        audioContextRef.current.close();
        audioContextRef.current = null;
      }
      
      // åœæ­¢è®¡æ—¶
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      
      // åœæ­¢éŸ³é¢‘çº§åˆ«ç›‘æµ‹
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
        animationRef.current = null;
      }
      
      setRecordingState(prev => ({
        ...prev,
        isRecording: false,
        audioLevel: 0
      }));
      
      console.log('å½•åˆ¶åœæ­¢');
    }
  };

  // æš‚åœ/æ¢å¤å½•åˆ¶
  const togglePause = () => {
    if (mediaRecorderRef.current) {
      if (recordingState.isPaused) {
        mediaRecorderRef.current.resume();
        timerRef.current = setInterval(() => {
          setRecordingState(prev => ({ ...prev, duration: prev.duration + 1 }));
        }, 1000);
      } else {
        mediaRecorderRef.current.pause();
        if (timerRef.current) {
          clearInterval(timerRef.current);
        }
      }
      
      setRecordingState(prev => ({ ...prev, isPaused: !prev.isPaused }));
    }
  };

  // å¤„ç†å½•åˆ¶åœæ­¢
  const handleRecordingStop = async () => {
    const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' });
    
    setRecordingState(prev => ({
      ...prev,
      isRecording: false,
      isPaused: false,
      audioLevel: 0
    }));
    
    onRecordingStop?.(audioBlob);
    
    // å¦‚æœè®¾ç½®äº†è‡ªåŠ¨æäº¤ï¼Œç›´æ¥ä¸Šä¼ è¯†åˆ«
    if (voiceSettings.autoSubmit) {
      await uploadAndTranscribe(audioBlob);
    }
  };

  // ä¸Šä¼ å¹¶è¯†åˆ«éŸ³é¢‘
  const uploadAndTranscribe = async (audioBlob: Blob) => {
    try {
      setIsUploading(true);
      setIsProcessing(true);

      const formData = new FormData();
      formData.append('audio', audioBlob, `recording-${Date.now()}.webm`);
      formData.append('language', voiceSettings.language);
      formData.append('model', voiceSettings.model);

      const response = await fetch('/api/voice/upload', {
        method: 'POST',
        body: formData,
        credentials: 'include'
      });

      const result = await response.json();
      
      if (result.success) {
        const { text, confidence } = result.data;
        
        // æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆå€¼
        if (confidence >= voiceSettings.confidenceThreshold) {
          onTranscriptionComplete?.(text, confidence);
        } else {
          onError?.(`è¯­éŸ³è¯†åˆ«ç½®ä¿¡åº¦è¾ƒä½ (${(confidence * 100).toFixed(1)}%)ï¼Œè¯·é‡æ–°å½•åˆ¶`);
        }
      } else {
        onError?.(result.message || 'è¯­éŸ³è¯†åˆ«å¤±è´¥');
      }
    } catch (error) {
      console.error('ä¸Šä¼ éŸ³é¢‘å¤±è´¥:', error);
      onError?.('ä¸Šä¼ éŸ³é¢‘å¤±è´¥ï¼Œè¯·é‡è¯•');
    } finally {
      setIsUploading(false);
      setIsProcessing(false);
    }
  };

  // æ‰‹åŠ¨ä¸Šä¼ è¯†åˆ«
  const handleUpload = () => {
    if (chunksRef.current.length > 0) {
      const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' });
      uploadAndTranscribe(audioBlob);
    }
  };

  // éŸ³é¢‘çº§åˆ«ç›‘æµ‹
  const startAudioLevelMonitoring = () => {
    if (!analyserRef.current) return;

    const analyser = analyserRef.current;
    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    const updateAudioLevel = () => {
      if (!recordingState.isRecording) return;

      analyser.getByteFrequencyData(dataArray);
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
      const normalizedLevel = Math.min(100, (average / 128) * 100);

      setRecordingState(prev => ({ ...prev, audioLevel: normalizedLevel }));

      animationRef.current = requestAnimationFrame(updateAudioLevel);
    };

    updateAudioLevel();
  };

  // è·å–æ”¯æŒçš„åª’ä½“ç±»å‹
  const getSupportedMimeType = () => {
    const types = [
      'audio/webm',
      'audio/mp4',
      'audio/ogg',
      'audio/wav'
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        return type;
      }
    }

    return 'audio/webm';
  };

  // æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // è·å–æŒ‰é’®æ ·å¼
  const getButtonStyle = () => {
    const baseStyle = "px-4 py-2 rounded-lg font-medium transition-all duration-200 flex items-center space-x-2";
    
    if (recordingState.isRecording) {
      return `${baseStyle} bg-red-600 hover:bg-red-700 text-white`;
    }
    
    return `${baseStyle} bg-blue-600 hover:bg-blue-700 text-white`;
  };

  return (
    <div className={`voice-recorder ${className}`}>
      {/* å½•åˆ¶æ§åˆ¶æŒ‰é’® */}
      <div className="flex items-center space-x-3">
        {!recordingState.isRecording ? (
          <button
            onClick={startRecording}
            disabled={isUploading || isProcessing}
            className={getButtonStyle()}
          >
            <span>ğŸ¤</span>
            <span>å¼€å§‹å½•åˆ¶</span>
          </button>
        ) : (
          <>
            <button
              onClick={stopRecording}
              className="px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-lg font-medium transition-all duration-200 flex items-center space-x-2"
            >
              <span>â¹ï¸</span>
              <span>åœæ­¢å½•åˆ¶</span>
            </button>
            
            <button
              onClick={togglePause}
              className="px-3 py-2 bg-yellow-600 hover:bg-yellow-700 text-white rounded-lg font-medium transition-all duration-200"
            >
              {recordingState.isPaused ? 'â–¶ï¸' : 'â¸ï¸'}
            </button>
          </>
        )}
        
        {/* ä¸Šä¼ æŒ‰é’® */}
        {!recordingState.isRecording && chunksRef.current.length > 0 && !voiceSettings.autoSubmit && (
          <button
            onClick={handleUpload}
            disabled={isUploading}
            className="px-4 py-2 bg-green-600 hover:bg-green-700 text-white rounded-lg font-medium transition-all duration-200 flex items-center space-x-2 disabled:opacity-50"
          >
            <span>ğŸ“¤</span>
            <span>{isUploading ? 'ä¸Šä¼ ä¸­...' : 'è¯†åˆ«è¯­éŸ³'}</span>
          </button>
        )}
      </div>

      {/* å½•åˆ¶çŠ¶æ€æ˜¾ç¤º */}
      {(recordingState.isRecording || recordingState.duration > 0) && (
        <div className="mt-4 p-4 bg-gray-800/50 rounded-lg border border-gray-700">
          <div className="flex items-center justify-between mb-3">
            <div className="flex items-center space-x-3">
              <div className={`w-3 h-3 rounded-full ${recordingState.isRecording ? 'bg-red-500 animate-pulse' : 'bg-gray-500'}`} />
              <span className="text-sm font-medium">
                {recordingState.isRecording ? 'å½•åˆ¶ä¸­' : 'å·²åœæ­¢'} {recordingState.isPaused && '(å·²æš‚åœ)'}
              </span>
              <span className="text-sm text-gray-400">
                {formatTime(recordingState.duration)}
              </span>
            </div>
            
            <div className="text-sm text-gray-400">
              æœ€å¤§æ—¶é•¿: {formatTime(maxDuration)}
            </div>
          </div>
          
          {/* éŸ³é¢‘çº§åˆ«æŒ‡ç¤ºå™¨ */}
          {recordingState.isRecording && (
            <div className="space-y-2">
              <div className="text-xs text-gray-400">éŸ³é¢‘çº§åˆ«</div>
              <div className="w-full h-2 bg-gray-700 rounded-full overflow-hidden">
                <div
                  className="h-full bg-green-500 transition-all duration-100"
                  style={{ width: `${recordingState.audioLevel}%` }}
                />
              </div>
            </div>
          )}
          
          {/* å¤„ç†çŠ¶æ€ */}
          {(isUploading || isProcessing) && (
            <div className="mt-3 flex items-center space-x-2 text-sm text-blue-400">
              <div className="w-4 h-4 border-2 border-blue-400 border-t-transparent rounded-full animate-spin" />
              <span>
                {isUploading ? 'ä¸Šä¼ éŸ³é¢‘ä¸­...' : 'è¯­éŸ³è¯†åˆ«ä¸­...'}
              </span>
            </div>
          )}
        </div>
      )}

      {/* è¯­éŸ³è®¾ç½®æ˜¾ç¤º */}
      <div className="mt-3 text-xs text-gray-500 flex items-center space-x-4">
        <span>è¯­è¨€: {voiceSettings.language}</span>
        <span>æ¨¡å‹: {voiceSettings.model}</span>
        <span>ç½®ä¿¡åº¦é˜ˆå€¼: {(voiceSettings.confidenceThreshold * 100).toFixed(0)}%</span>
        {voiceSettings.autoSubmit && <span className="text-blue-400">è‡ªåŠ¨æäº¤</span>}
      </div>
    </div>
  );
};
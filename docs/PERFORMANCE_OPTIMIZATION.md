# AiDesign æ€§èƒ½ä¼˜åŒ–æŒ‡å—

## ğŸ“‹ ç›®å½•

- [æ€§èƒ½ç›‘æ§](#æ€§èƒ½ç›‘æ§)
- [åº”ç”¨å±‚ä¼˜åŒ–](#åº”ç”¨å±‚ä¼˜åŒ–)
- [æ•°æ®åº“ä¼˜åŒ–](#æ•°æ®åº“ä¼˜åŒ–)
- [ç¼“å­˜ä¼˜åŒ–](#ç¼“å­˜ä¼˜åŒ–)
- [å‰ç«¯ä¼˜åŒ–](#å‰ç«¯ä¼˜åŒ–)
- [ç½‘ç»œä¼˜åŒ–](#ç½‘ç»œä¼˜åŒ–)
- [ç³»ç»Ÿçº§ä¼˜åŒ–](#ç³»ç»Ÿçº§ä¼˜åŒ–)
- [ç›‘æ§å’Œè°ƒä¼˜](#ç›‘æ§å’Œè°ƒä¼˜)

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å…³é”®æ€§èƒ½æŒ‡æ ‡

#### åº”ç”¨æ€§èƒ½æŒ‡æ ‡ (APM)

**å“åº”æ—¶é—´æŒ‡æ ‡**
```javascript
// å“åº”æ—¶é—´åˆ†çº§
const responseTimeMetrics = {
    excellent: '< 100ms',    // ä¼˜ç§€
    good: '100ms - 300ms', // è‰¯å¥½  
    acceptable: '300ms - 1s', // å¯æ¥å—
    poor: '> 1s'           // éœ€è¦ä¼˜åŒ–
};

// APIæ€§èƒ½åŸºå‡†
const apiBenchmarks = {
    '/api/health': { target: '< 50ms', p95: '< 100ms' },
    '/api/auth/login': { target: '< 200ms', p95: '< 500ms' },
    '/api/ai/chat': { target: '< 2s', p95: '< 5s' },
    '/api/ai/image/generate': { target: '< 30s', p95: '< 60s' },
    '/api/files/upload': { target: '< 5s', p95: '< 10s' }
};
```

**ååé‡æŒ‡æ ‡**
```javascript
// å¹¶å‘ç”¨æˆ·æ•°ç›®æ ‡
const concurrentUsers = {
    minimum: 100,     // æœ€ä½è¦æ±‚
    standard: 1000,    // æ ‡å‡†é…ç½®
    high: 10000,       // é«˜è´Ÿè½½é…ç½®
    enterprise: 100000  // ä¼ä¸šçº§é…ç½®
};

// è¯·æ±‚å¤„ç†èƒ½åŠ›
const throughputTargets = {
    requestsPerSecond: {
        web: 1000,      // Webé¡µé¢è¯·æ±‚
        api: 5000,      // APIè¯·æ±‚
        file: 100,       // æ–‡ä»¶ä¸Šä¼ 
        ai: 50          // AIå¤„ç†è¯·æ±‚
    }
};
```

#### ç³»ç»Ÿèµ„æºæŒ‡æ ‡

**CPUä½¿ç”¨ç‡**
```bash
# CPUä½¿ç”¨ç‡ç›®æ ‡
CPU_USAGE_TARGETS = {
    warning: 70,    // è­¦å‘Šé˜ˆå€¼
    critical: 85,    // ä¸¥é‡é˜ˆå€¼
    optimal: 60      // æœ€ä¼˜èŒƒå›´
}

# ç›‘æ§è„šæœ¬
#!/bin/bash
cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')

if (( $(echo "$cpu_usage > $CPU_WARNING" | bc -l) )); then
    echo "WARNING: CPU usage is ${cpu_usage}%"
elif (( $(echo "$cpu_usage > $CPU_CRITICAL" | bc -l) )); then
    echo "CRITICAL: CPU usage is ${cpu_usage}%"
fi
```

**å†…å­˜ä½¿ç”¨ç‡**
```bash
# å†…å­˜ä½¿ç”¨ç›‘æ§
memory_monitor() {
    local total=$(free -m | awk 'NR==2{print $2}')
    local used=$(free -m | awk 'NR==2{print $3}')
    local usage=$((used * 100 / total))
    
    echo "Memory usage: ${usage}% (${used}MB/${total}MB)"
    
    if [ $usage -gt 85 ]; then
        echo "CRITICAL: High memory usage detected"
    elif [ $usage -gt 70 ]; then
        echo "WARNING: Memory usage is high"
    fi
}
```

### æ€§èƒ½ç›‘æ§å·¥å…·

#### PrometheusæŒ‡æ ‡é…ç½®

**åº”ç”¨æŒ‡æ ‡**
```yaml
# custom_metrics.yml
groups:
  - name: aiplatform.application
    rules:
      # å“åº”æ—¶é—´æŒ‡æ ‡
      - record: aiplatform:http_request_duration_seconds:rate5m
        expr: rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])
      
      # é”™è¯¯ç‡æŒ‡æ ‡
      - record: aiplatform:http_request_error_rate:rate5m
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])
      
      # å¹¶å‘ç”¨æˆ·æ•°
      - record: aiplatform:concurrent_users
        expr: count by (user_id) (user_last_seen_timestamp)
```

**ä¸šåŠ¡æŒ‡æ ‡**
```yaml
# business_metrics.yml
groups:
  - name: aiplatform.business
    rules:
      # AIä½¿ç”¨ç»Ÿè®¡
      - record: aiplatform:ai_requests_per_minute
        expr: increase(ai_requests_total[1m])
      
      # æ–‡ä»¶å¤„ç†é‡
      - record: aiplatform:files_processed_per_minute
        expr: increase(files_processed_total[1m])
      
      # æ´»è·ƒé¡¹ç›®æ•°
      - record: aiplatform:active_projects
        expr: count(project_last_updated_timestamp > time() - 3600)
```

## ğŸš€ åº”ç”¨å±‚ä¼˜åŒ–

### Node.jsæ€§èƒ½ä¼˜åŒ–

#### äº‹ä»¶å¾ªç¯ä¼˜åŒ–

```javascript
// å¯ç”¨é›†ç¾¤æ¨¡å¼
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
    console.log(`Master ${process.pid} is running`);
    
    // Fork workers
    for (let i = 0; i < numCPUs; i++) {
        cluster.fork();
    }
    
    cluster.on('exit', (worker, code, signal) => {
        console.log(`Worker ${worker.process.pid} died`);
        cluster.fork(); // Restart worker
    });
} else {
    // Worker process
    require('./app');
    
    // ä¼˜é›…å…³é—­
    process.on('SIGTERM', () => {
        console.log(`Worker ${process.pid} shutting down gracefully`);
        server.close(() => {
            process.exit(0);
        });
    });
}
```

#### å†…å­˜ç®¡ç†ä¼˜åŒ–

```javascript
// å†…å­˜æ³„æ¼æ£€æµ‹
const memwatch = require('memwatch-next');

memwatch.on('leak', (info) => {
    console.error('Memory leak detected:', info);
    // å‘é€å‘Šè­¦
    sendAlert('Memory leak detected', info);
});

memwatch.on('stats', (stats) => {
    if (stats.current_base_size > 100 * 1024 * 1024) { // 100MB
        console.warn('High memory usage detected:', stats);
    }
});

// å¯¹è±¡æ± ä¼˜åŒ–
class ObjectPool {
    constructor(createFn, resetFn, maxSize = 100) {
        this.createFn = createFn;
        this.resetFn = resetFn;
        this.maxSize = maxSize;
        this.pool = [];
    }
    
    acquire() {
        if (this.pool.length > 0) {
            return this.pool.pop();
        }
        return this.createFn();
    }
    
    release(obj) {
        if (this.pool.length < this.maxSize) {
            this.resetFn(obj);
            this.pool.push(obj);
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
const stringPool = new ObjectPool(
    () => new Array(1000).join(''),
    (arr) => arr.length = 0,
    50
);
```

#### æ•°æ®åº“è¿æ¥ä¼˜åŒ–

```javascript
// è¿æ¥æ± é…ç½®
const { Pool } = require('pg');

const poolConfig = {
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    database: process.env.POSTGRES_DB,
    user: process.env.POSTGRES_USER,
    password: process.env.POSTGRES_PASSWORD,
    max: 20,              // æœ€å¤§è¿æ¥æ•°
    min: 5,               // æœ€å°è¿æ¥æ•°
    idleTimeoutMillis: 30000, // ç©ºé—²è¶…æ—¶30ç§’
    connectionTimeoutMillis: 2000, // è¿æ¥è¶…æ—¶2ç§’
    acquireTimeoutMillis: 60000,   // è·å–è¿æ¥è¶…æ—¶60ç§’
    createTimeoutMillis: 30000,     // åˆ›å»ºè¿æ¥è¶…æ—¶30ç§’
    destroyTimeoutMillis: 5000,    // é”€æ¯è¿æ¥è¶…æ—¶5ç§’
    reapIntervalMillis: 1000,       // å›æ”¶é—´éš”1ç§’
    createRetryIntervalMillis: 200   // åˆ›å»ºé‡è¯•é—´éš”200ms
};

const pool = new Pool(poolConfig);

// ç›‘æ§è¿æ¥æ± çŠ¶æ€
pool.on('connect', (client) => {
    console.log('New connection established');
});

pool.on('remove', (client) => {
    console.log('Connection removed');
});

pool.on('error', (err, client) => {
    console.error('Pool error:', err);
});

// è¿æ¥æŸ¥è¯¢ä¸­é—´ä»¶
app.use(async (req, res, next) => {
    const client = await pool.connect();
    req.db = client;
    
    res.on('finish', () => {
        client.release();
    });
    
    next();
});
```

### APIæ€§èƒ½ä¼˜åŒ–

#### è¯·æ±‚å¤„ç†ä¼˜åŒ–

```javascript
// å‹ç¼©ä¸­é—´ä»¶
const compression = require('compression');
app.use(compression({
    filter: (req, res) => {
        if (req.headers['x-no-compression']) {
            return false;
        }
        return compression.filter(req, res);
    },
    level: 6,
    threshold: 1024,
    chunkSize: 16 * 1024
}));

// å“åº”ç¼“å­˜ä¸­é—´ä»¶
const cache = require('memory-cache');
const responseCache = new cache({
    max: 1000,
    ttl: 300 * 1000, // 5åˆ†é’Ÿ
    checkperiod: 60 * 1000 // 1åˆ†é’Ÿæ£€æŸ¥è¿‡æœŸ
});

const cacheMiddleware = (req, res, next) => {
    const key = req.originalUrl;
    const cached = responseCache.get(key);
    
    if (cached) {
        res.set('X-Cache', 'HIT');
        return res.json(cached);
    }
    
    res.set('X-Cache', 'MISS');
    
    // é‡å†™res.jsonä»¥ç¼“å­˜å“åº”
    const originalJson = res.json;
    res.json = function(data) {
        if (res.statusCode === 200) {
            responseCache.set(key, data, 60); // ç¼“å­˜1åˆ†é’Ÿ
        }
        return originalJson.call(this, data);
    };
    
    next();
};

// æ‰¹é‡è¯·æ±‚ä¼˜åŒ–
const batchProcessing = async (requests) => {
    const batchSize = 10;
    const results = [];
    
    for (let i = 0; i < requests.length; i += batchSize) {
        const batch = requests.slice(i, i + batchSize);
        const batchResults = await Promise.all(
            batch.map(req => processRequest(req))
        );
        results.push(...batchResults);
        
        // é¿å…è¿‡è½½ï¼Œæ‰¹æ¬¡é—´æš‚åœ
        if (i + batchSize < requests.length) {
            await new Promise(resolve => setTimeout(resolve, 100));
        }
    }
    
    return results;
};
```

#### å¼‚æ­¥å¤„ç†ä¼˜åŒ–

```javascript
// ä»»åŠ¡é˜Ÿåˆ—é…ç½®
const Queue = require('bull');
const redisConfig = {
    host: process.env.REDIS_HOST,
    port: process.env.REDIS_PORT,
    maxRetriesPerRequest: 3,
    retryDelay: 5000
};

// åˆ›å»ºä¸åŒç±»å‹çš„é˜Ÿåˆ—
const aiQueue = new Queue('AI processing', { redis: redisConfig });
const fileQueue = new Queue('File processing', { redis: redisConfig });
const emailQueue = new Queue('Email sending', { redis: redisConfig });

// AIå¤„ç†é˜Ÿåˆ—é…ç½®
aiQueue.process(5, async (job) => {
    const { type, data } = job.data;
    
    try {
        switch (type) {
            case 'image_generation':
                return await generateImage(data);
            case 'text_generation':
                return await generateText(data);
            case 'speech_synthesis':
                return await synthesizeSpeech(data);
            default:
                throw new Error(`Unknown AI task type: ${type}`);
        }
    } catch (error) {
        console.error(`AI job ${job.id} failed:`, error);
        throw error; // Bullä¼šè‡ªåŠ¨é‡è¯•
    }
});

// é˜Ÿåˆ—ç›‘æ§
aiQueue.on('completed', (job, result) => {
    console.log(`AI job ${job.id} completed`);
});

aiQueue.on('failed', (job, err) => {
    console.error(`AI job ${job.id} failed:`, err);
});

aiQueue.on('stalled', (job) => {
    console.warn(`AI job ${job.id} stalled`);
});
```

## ğŸ—„ï¸ æ•°æ®åº“ä¼˜åŒ–

### PostgreSQLæ€§èƒ½è°ƒä¼˜

#### é…ç½®ä¼˜åŒ–

```sql
-- postgresql.conf æ€§èƒ½å‚æ•°ä¼˜åŒ–

-- å†…å­˜é…ç½®
shared_buffers = 256MB                    -- 25% of RAM on dedicated server
effective_cache_size = 1GB                 -- 75% of RAM on dedicated server
work_mem = 4MB                             -- Per connection memory
maintenance_work_mem = 64MB                   -- Maintenance operations

-- è¿æ¥é…ç½®
max_connections = 200                         -- æ ¹æ®åº”ç”¨éœ€æ±‚è°ƒæ•´
shared_preload_libraries = 'pg_stat_statements'   -- é¢„åŠ è½½ç»Ÿè®¡æ¨¡å—
pg_stat_statements.track = all                  -- è·Ÿè¸ªæ‰€æœ‰æŸ¥è¯¢

-- WALé…ç½®
wal_buffers = 16MB                           -- WALç¼“å†²åŒº
checkpoint_completion_target = 0.7              -- æ£€æŸ¥ç‚¹å®Œæˆç›®æ ‡
wal_writer_delay = 10ms                      -- WALå†™å…¥å»¶è¿Ÿ

-- æŸ¥è¯¢è§„åˆ’å™¨
random_page_cost = 1.1                         -- SSDä¼˜åŒ–
effective_io_concurrency = 200                  -- å¹¶å‘IOæ“ä½œ
default_statistics_target = 100                -- ç»Ÿè®¡ç›®æ ‡

-- æ—¥å¿—é…ç½®
log_min_duration_statement = 1000               -- è®°å½•æ…¢æŸ¥è¯¢ (>1s)
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
```

#### ç´¢å¼•ä¼˜åŒ–

```sql
-- åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE users;
ANALYZE projects;
ANALYZE ai_requests;

-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX CONCURRENTLY idx_users_email_status 
ON users(email, status) WHERE status IS NOT NULL;

CREATE INDEX CONCURRENTLY idx_projects_user_updated 
ON projects(user_id, updated_at DESC);

CREATE INDEX CONCURRENTLY idx_ai_requests_user_created 
ON ai_requests(user_id, created_at DESC);

-- éƒ¨åˆ†ç´¢å¼•ï¼ˆå¯¹å¤§è¡¨æœ‰æ•ˆï¼‰
CREATE INDEX CONCURRENTLY idx_ai_requests_recent 
ON ai_requests(created_at) WHERE created_at > NOW() - INTERVAL '30 days';

-- è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_users_lower_email 
ON users(LOWER(email));

-- JSONå­—æ®µç´¢å¼•
CREATE INDEX CONCURRENTLY idx_ai_requests_data_gin 
ON ai_requests USING gin(data);
```

#### æŸ¥è¯¢ä¼˜åŒ–

```sql
-- æŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹

-- åŸå§‹æŸ¥è¯¢ï¼ˆå¯èƒ½å¾ˆæ…¢ï¼‰
SELECT u.*, p.* 
FROM users u 
LEFT JOIN projects p ON u.id = p.user_id 
WHERE u.email = 'user@example.com' 
ORDER BY p.created_at DESC;

-- ä¼˜åŒ–åæŸ¥è¯¢
EXPLAIN (ANALYZE, BUFFERS)
SELECT u.id, u.email, u.name, 
       p.id as project_id, p.name as project_name, p.created_at
FROM users u
LEFT JOIN LATERAL (
    SELECT id, name, created_at
    FROM projects 
    WHERE user_id = u.id 
    ORDER BY created_at DESC 
    LIMIT 10
) p ON true
WHERE u.email = 'user@example.com';

-- ä½¿ç”¨CTEä¼˜åŒ–å¤æ‚æŸ¥è¯¢
WITH user_projects AS (
    SELECT u.id, u.email,
           p.id as project_id, p.name as project_name, p.created_at
    FROM users u
    LEFT JOIN projects p ON u.id = p.user_id
    WHERE u.email = 'user@example.com'
),
project_stats AS (
    SELECT user_id, 
           COUNT(*) as project_count,
           MAX(created_at) as latest_project
    FROM projects
    GROUP BY user_id
)
SELECT up.*, ps.project_count
FROM user_projects up
JOIN project_stats ps ON up.id = ps.user_id;
```

#### åˆ†åŒºè¡¨ä¼˜åŒ–

```sql
-- æ—¶é—´åˆ†åŒºè¡¨ç¤ºä¾‹
CREATE TABLE ai_requests (
    id SERIAL,
    user_id INTEGER NOT NULL,
    type VARCHAR(50) NOT NULL,
    status VARCHAR(20) NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    data JSONB
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºæœˆåº¦åˆ†åŒº
CREATE TABLE ai_requests_2024_01 PARTITION OF ai_requests
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE ai_requests_2024_02 PARTITION OF ai_requests
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- è‡ªåŠ¨åˆ›å»ºåˆ†åŒºçš„å­˜å‚¨è¿‡ç¨‹
CREATE OR REPLACE FUNCTION create_monthly_partition(table_name text, start_date date)
RETURNS void AS $$
DECLARE
    partition_name text;
    end_date date;
BEGIN
    partition_name := table_name || '_' || to_char(start_date, 'YYYY_MM');
    end_date := start_date + interval '1 month';
    
    EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF %I
                    FOR VALUES FROM (%L) TO (%L)',
                   partition_name, table_name, start_date, end_date);
END;
$$ LANGUAGE plpgsql;

-- å®šæœŸåˆ›å»ºæ–°åˆ†åŒº
SELECT create_monthly_partition('ai_requests', date_trunc('month', CURRENT_DATE + interval '1 month'));
```

## ğŸ—„ï¸ ç¼“å­˜ä¼˜åŒ–

### Redisç¼“å­˜ç­–ç•¥

#### ç¼“å­˜æ¶æ„è®¾è®¡

```javascript
// ç¼“å­˜å±‚çº§æ¶æ„
const cacheStrategy = {
    // L1: åº”ç”¨å†…å­˜ç¼“å­˜ï¼ˆæœ€å¿«ï¼‰
    l1: {
        type: 'memory',
        ttl: 60,      // 1åˆ†é’Ÿ
        maxSize: 1000,
        keys: ['user_session', 'config', 'hot_data']
    },
    
    // L2: Redisç¼“å­˜ï¼ˆå¿«ï¼‰
    l2: {
        type: 'redis',
        ttl: 3600,    // 1å°æ—¶
        keys: ['user_profile', 'project_data', 'ai_results']
    },
    
    // L3: ç£ç›˜ç¼“å­˜ï¼ˆæŒä¹…ï¼‰
    l3: {
        type: 'disk',
        ttl: 86400,   // 24å°æ—¶
        keys: ['generated_images', 'large_files', 'backup_data']
    }
};

// å¤šçº§ç¼“å­˜å®ç°
class MultiLevelCache {
    constructor(l1Cache, l2Cache, l3Cache) {
        this.l1 = l1Cache;
        this.l2 = l2Cache;
        this.l3 = l3Cache;
    }
    
    async get(key) {
        // å°è¯•L1ç¼“å­˜
        let value = await this.l1.get(key);
        if (value !== null) {
            return { value, source: 'l1' };
        }
        
        // å°è¯•L2ç¼“å­˜
        value = await this.l2.get(key);
        if (value !== null) {
            // å›å¡«L1ç¼“å­˜
            await this.l1.set(key, value, 60);
            return { value, source: 'l2' };
        }
        
        // å°è¯•L3ç¼“å­˜
        value = await this.l3.get(key);
        if (value !== null) {
            // å›å¡«L1å’ŒL2ç¼“å­˜
            await this.l1.set(key, value, 60);
            await this.l2.set(key, value, 3600);
            return { value, source: 'l3' };
        }
        
        return { value: null, source: 'miss' };
    }
    
    async set(key, value, ttl = 3600) {
        await Promise.all([
            this.l1.set(key, value, Math.min(ttl, 60)),
            this.l2.set(key, value, ttl),
            this.l3.set(key, value, Math.max(ttl, 86400))
        ]);
    }
}
```

#### ç¼“å­˜é”®è®¾è®¡

```javascript
// ç¼“å­˜é”®å‘½åè§„èŒƒ
const cacheKeys = {
    user: (userId) => `user:${userId}`,
    userProfile: (userId) => `user:${userId}:profile`,
    userSession: (sessionId) => `session:${sessionId}`,
    project: (projectId) => `project:${projectId}`,
    projectMembers: (projectId) => `project:${projectId}:members`,
    aiModel: (modelId) => `ai:model:${modelId}`,
    aiResult: (requestId) => `ai:result:${requestId}`,
    fileMeta: (fileId) => `file:${fileId}:meta`,
    permissions: (userId, resource) => `perm:${userId}:${resource}`,
    rateLimit: (userId, endpoint) => `rate:${userId}:${endpoint}`,
    config: (key) => `config:${key}`
};

// ç¼“å­˜å¤±æ•ˆç­–ç•¥
const cacheInvalidation = {
    // ç”¨æˆ·ç›¸å…³ç¼“å­˜å¤±æ•ˆ
    invalidateUser: async (userId) => {
        const patterns = [
            `user:${userId}*`,
            `session:*${userId}*`,
            `perm:${userId}*`
        ];
        
        for (const pattern of patterns) {
            await invalidatePattern(pattern);
        }
    },
    
    // é¡¹ç›®ç›¸å…³ç¼“å­˜å¤±æ•ˆ
    invalidateProject: async (projectId) => {
        const patterns = [
            `project:${projectId}*`,
            `file:*project:${projectId}*`
        ];
        
        for (const pattern of patterns) {
            await invalidatePattern(pattern);
        }
    }
};
```

#### ç¼“å­˜é¢„çƒ­ç­–ç•¥

```javascript
// åº”ç”¨å¯åŠ¨æ—¶é¢„çƒ­å…³é”®æ•°æ®
const cacheWarmup = async () => {
    console.log('Starting cache warmup...');
    
    // é¢„çƒ­ç”¨æˆ·é…ç½®
    const activeUsers = await getActiveUsers();
    for (const user of activeUsers) {
        const profile = await getUserProfile(user.id);
        await cache.set(cacheKeys.userProfile(user.id), profile, 3600);
    }
    
    // é¢„çƒ­çƒ­é—¨é¡¹ç›®
    const hotProjects = await getHotProjects();
    for (const project of hotProjects) {
        const projectData = await getProjectDetails(project.id);
        await cache.set(cacheKeys.project(project.id), projectData, 1800);
    }
    
    // é¢„çƒ­AIæ¨¡å‹é…ç½®
    const aiModels = await getAIModels();
    for (const model of aiModels) {
        await cache.set(cacheKeys.aiModel(model.id), model.config, 86400);
    }
    
    console.log('Cache warmup completed');
};

// å®šæœŸé¢„çƒ­
setInterval(async () => {
    const stats = await getCacheStats();
    if (stats.hitRate < 0.8) {
        console.log('Cache hit rate low, triggering warmup');
        await cacheWarmup();
    }
}, 300000); // 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
```

## ğŸ¨ å‰ç«¯ä¼˜åŒ–

### Reactæ€§èƒ½ä¼˜åŒ–

#### ç»„ä»¶ä¼˜åŒ–

```typescript
// ä½¿ç”¨React.memoä¼˜åŒ–ç»„ä»¶æ¸²æŸ“
import React, { memo, useMemo, useCallback } from 'react';

interface UserListProps {
    users: User[];
    onUserSelect: (user: User) => void;
}

const UserList = memo<UserListProps>(({ users, onUserSelect }) => {
    // ä½¿ç”¨useMemoç¼“å­˜è®¡ç®—ç»“æœ
    const sortedUsers = useMemo(() => {
        return users.sort((a, b) => a.name.localeCompare(b.name));
    }, [users]);
    
    // ä½¿ç”¨useCallbackç¼“å­˜å‡½æ•°
    const handleUserSelect = useCallback((user: User) => {
        onUserSelect(user);
    }, [onUserSelect]);
    
    return (
        <div>
            {sortedUsers.map(user => (
                <UserItem 
                    key={user.id} 
                    user={user} 
                    onSelect={handleUserSelect}
                />
            ))}
        </div>
    );
});

// ä½¿ç”¨useSelectorä¼˜åŒ–çŠ¶æ€è®¢é˜…
import { useSelector, useDispatch } from 'react-redux';

const UserProfile = () => {
    // åªè®¢é˜…éœ€è¦çš„çŠ¶æ€ç‰‡æ®µ
    const user = useSelector(state => state.user.profile);
    const loading = useSelector(state => state.user.loading);
    const dispatch = useDispatch();
    
    const handleUpdate = useCallback((updates: Partial<User>) => {
        dispatch(updateUserProfile(updates));
    }, [dispatch]);
    
    if (loading) return <LoadingSpinner />;
    
    return <UserProfileForm user={user} onUpdate={handleUpdate} />;
};
```

#### ä»£ç åˆ†å‰²å’Œæ‡’åŠ è½½

```typescript
// è·¯ç”±çº§åˆ«çš„ä»£ç åˆ†å‰²
import { lazy, Suspense } from 'react';
import { Routes, Route } from 'react-router-dom';

// æ‡’åŠ è½½ç»„ä»¶
const AIDashboard = lazy(() => import('./pages/AIDashboard'));
const ProjectManager = lazy(() => import('./pages/ProjectManager'));
const WorkflowDesigner = lazy(() => import('./pages/WorkflowDesigner'));

const App = () => (
    <Suspense fallback={<div>Loading...</div>}>
        <Routes>
            <Route path="/ai" element={<AIDashboard />} />
            <Route path="/projects" element={<ProjectManager />} />
            <Route path="/workflows" element={<WorkflowDesigner />} />
        </Routes>
    </Suspense>
);

// ç»„ä»¶çº§åˆ«çš„æ‡’åŠ è½½
const HeavyChart = lazy(() => 
    import('./components/HeavyChart').then(module => ({
        default: module.HeavyChart
    }))
);

// åŠ¨æ€å¯¼å…¥
const loadFeatureModule = async (featureName: string) => {
    try {
        const module = await import(`./features/${featureName}`);
        return module.default;
    } catch (error) {
        console.error(`Failed to load feature ${featureName}:`, error);
        return null;
    }
};
```

### èµ„æºä¼˜åŒ–

#### å›¾ç‰‡ä¼˜åŒ–

```typescript
// å›¾ç‰‡æ‡’åŠ è½½ç»„ä»¶
import React, { useState, useRef, useEffect } from 'react';

interface LazyImageProps {
    src: string;
    alt: string;
    placeholder?: string;
    className?: string;
}

const LazyImage: React.FC<LazyImageProps> = ({ 
    src, 
    alt, 
    placeholder = '/images/placeholder.jpg',
    className 
}) => {
    const [isLoaded, setIsLoaded] = useState(false);
    const [isInView, setIsInView] = useState(false);
    const imgRef = useRef<HTMLImageElement>(null);
    
    useEffect(() => {
        const observer = new IntersectionObserver(
            ([entry]) => {
                if (entry.isIntersecting) {
                    setIsInView(true);
                    observer.disconnect();
                }
            },
            { threshold: 0.1 }
        );
        
        if (imgRef.current) {
            observer.observe(imgRef.current);
        }
        
        return () => observer.disconnect();
    }, []);
    
    return (
        <img
            ref={imgRef}
            src={isInView ? src : placeholder}
            alt={alt}
            className={className}
            loading="lazy"
            onLoad={() => setIsLoaded(true)}
            style={{
                transition: 'opacity 0.3s',
                opacity: isLoaded ? 1 : 0.7
            }}
        />
    );
};

// å“åº”å¼å›¾ç‰‡ç»„ä»¶
const ResponsiveImage: React.FC<{
    sources: {
        srcSet: string;
        media?: string;
    }[];
    fallbackSrc: string;
    alt: string;
}> = ({ sources, fallbackSrc, alt }) => {
    return (
        <picture>
            {sources.map((source, index) => (
                <source
                    key={index}
                    srcSet={source.srcSet}
                    media={source.media}
                />
            ))}
            <img 
                src={fallbackSrc} 
                alt={alt}
                loading="lazy"
                decoding="async"
            />
        </picture>
    );
};
```

#### CSSä¼˜åŒ–

```css
/* CSSæ€§èƒ½ä¼˜åŒ– */

/* ä½¿ç”¨transformä»£æ›¿positionå˜åŒ– */
.optimized-animation {
    will-change: transform;
    transform: translateZ(0); /* å¯ç”¨GPUåŠ é€Ÿ */
    transition: transform 0.3s ease;
}

/* é¿å…é‡æ’å’Œé‡ç»˜ */
.layout-optimized {
    contain: layout style paint;
    overflow: hidden;
}

/* è™šæ‹Ÿæ»šåŠ¨ä¼˜åŒ– */
.virtual-list {
    height: 400px;
    overflow-y: auto;
    contain: strict;
}

.virtual-item {
    height: 60px;
    contain: layout;
}

/* CSS Gridä¼˜åŒ– */
.grid-optimized {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 20px;
    contain: layout;
}

/* å›¾ç‰‡ä¼˜åŒ– */
.responsive-image {
    content-visibility: auto;
    contain-intrinsic-size: 800px 600px;
}
```

### æ‰“åŒ…ä¼˜åŒ–

#### Webpacké…ç½®ä¼˜åŒ–

```javascript
// webpack.optimization.js
module.exports = {
    optimization: {
        splitChunks: {
            chunks: 'all',
            cacheGroups: {
                vendor: {
                    test: /[\\/]node_modules[\\/]/,
                    name: 'vendors',
                    chunks: 'all',
                    priority: 10
                },
                common: {
                    name: 'common',
                    minChunks: 2,
                    chunks: 'all',
                    priority: 5,
                    enforce: true
                },
                ai: {
                    test: /[\\/]src[\\/]features[\\/]ai[\\/]/,
                    name: 'ai',
                    chunks: 'all',
                    priority: 15
                }
            }
        },
        runtimeChunk: {
            name: 'runtime'
        },
        moduleIds: 'deterministic',
        usedExports: true,
        sideEffects: false
    },
    
    plugins: [
        new CompressionPlugin({
            algorithm: 'gzip',
            test: /\.(js|css|html|svg)$/,
            threshold: 8192,
            minRatio: 0.8
        }),
        
        new BundleAnalyzerPlugin({
            analyzerMode: 'static',
            openAnalyzer: false
        })
    ]
};
```

## ğŸŒ ç½‘ç»œä¼˜åŒ–

### CDNé…ç½®

```nginx
# nginx CDNé…ç½®
upstream cdn_backend {
    least_conn;
    server cdn1.aiplatform.com:80 weight=3;
    server cdn2.aiplatform.com:80 weight=2;
    server cdn3.aiplatform.com:80 weight=1 backup;
}

# é™æ€èµ„æºCDNé…ç½®
server {
    listen 80;
    server_name cdn.aiplatform.com;
    
    # ç¼“å­˜é…ç½®
    location ~* \.(jpg|jpeg|png|gif|ico|css|js|woff|woff2|ttf|svg)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
        add_header X-Cache-Status "HIT";
        
        # å‹ç¼©
        gzip_static on;
        gzip_types text/css application/javascript image/svg+xml;
        
        try_files $uri @cdn_backend;
    }
    
    # åŠ¨æ€å†…å®¹ä¸ç¼“å­˜
    location /api/ {
        proxy_pass http://backend;
        proxy_set_header X-Cache-Status "MISS";
        add_header Cache-Control "no-cache, no-store, must-revalidate";
    }
}
```

### è´Ÿè½½å‡è¡¡ä¼˜åŒ–

```nginx
# æ™ºèƒ½è´Ÿè½½å‡è¡¡
upstream api_backend {
    least_conn;
    server backend1:3000 weight=3 max_fails=3 fail_timeout=30s backup;
    server backend2:3000 weight=2 max_fails=3 fail_timeout=30s;
    server backend3:3000 weight=1 max_fails=3 fail_timeout=30s;
    
    # å¥åº·æ£€æŸ¥
    check interval=5000 rise=2 fall=3 timeout=30000 type=http;
    check_http_send "GET /health HTTP/1.0\r\n\r\n";
    check_http_expect_alive http_2xx http_3xx;
}

# è¿æ¥æ± ä¼˜åŒ–
server {
    listen 80;
    
    location /api/ {
        proxy_pass http://api_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # è¿æ¥ä¼˜åŒ–
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
        
        # ç¼“å†²ä¼˜åŒ–
        proxy_buffering on;
        proxy_buffer_size 8k;
        proxy_buffers 8 8k;
        proxy_busy_buffers_size 16k;
        
        # è¿æ¥æ± 
        keepalive 32;
    }
}
```

## ğŸ–¥ï¸ ç³»ç»Ÿçº§ä¼˜åŒ–

### å†…æ ¸å‚æ•°ä¼˜åŒ–

```bash
# /etc/sysctl.conf ä¼˜åŒ–é…ç½®

# ç½‘ç»œä¼˜åŒ–
net.core.rmem_max = 134217728          # 128MB
net.core.wmem_max = 134217728          # 128MB
net.ipv4.tcp_rmem = 4096 87380 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728
net.ipv4.tcp_congestion_control = bbr
net.ipv4.tcp_fastopen = 3
net.ipv4.tcp_fastopenq = 1024

# æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
fs.file-max = 2097152                # æœ€å¤§æ–‡ä»¶å¥æŸ„
fs.inotify.max_user_watches = 524288    # ç›‘æ§æ–‡ä»¶æ•°
vm.dirty_ratio = 15                     # è„é¡µæ¯”ä¾‹
vm.dirty_background_ratio = 5             # åå°å†™å…¥è„é¡µæ¯”ä¾‹
vm.swappiness = 10                     # swapä½¿ç”¨å€¾å‘

# è¿›ç¨‹ä¼˜åŒ–
kernel.pid_max = 4194304                # æœ€å¤§è¿›ç¨‹æ•°
kernel.threads-max = 262144            # æœ€å¤§çº¿ç¨‹æ•°

# åº”ç”¨é…ç½®
net.core.somaxconn = 65535             # æœ€å¤§ç›‘å¬é˜Ÿåˆ—
net.ipv4.ip_local_port_range = 1024 65535
```

### Dockerä¼˜åŒ–

```yaml
# docker-compose.yml ä¼˜åŒ–
version: '3.8'

services:
  backend:
    build:
      context: ./backend
      target: production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      - NODE_ENV=production
      - UV_THREADPOOL_SIZE=128
      - NODE_OPTIONS=--max-old-space-size=1536
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
```

## ğŸ“ˆ ç›‘æ§å’Œè°ƒä¼˜

### æ€§èƒ½ç›‘æ§å·¥å…·

#### åº”ç”¨æ€§èƒ½ç›‘æ§ (APM)

```javascript
// APMé›†æˆç¤ºä¾‹
const apm = require('elastic-apm-node').start({
    serviceName: 'aiplatform-backend',
    secretToken: process.env.ELASTIC_APM_SECRET,
    serverUrl: process.env.ELASTIC_APM_URL,
    environment: process.env.NODE_ENV,
    logLevel: 'info',
    captureBody: 'all',
    captureHeaders: true,
    transactionSampleRate: 0.1, // é‡‡æ ·10%
    captureSpanStackTraces: true,
    metricsInterval: 30,
    centralConfig: true
});

// è‡ªå®šä¹‰æ€§èƒ½æŒ‡æ ‡
const customMetrics = {
    // AIå¤„ç†æ—¶é—´
    aiProcessingTime: (duration, model) => {
        apm.setLabel('ai_model', model);
        apm.metrics('ai.processing.time', duration);
    },
    
    // ç¼“å­˜å‘½ä¸­ç‡
    cacheHitRate: (hits, total) => {
        const hitRate = hits / total;
        apm.metrics('cache.hit_rate', hitRate);
    },
    
    // æ•°æ®åº“è¿æ¥æ± çŠ¶æ€
    dbPoolStatus: (pool) => {
        apm.metrics('db.pool.total', pool.total);
        apm.metrics('db.pool.idle', pool.idle);
        apm.metrics('db.pool.waiting', pool.waiting);
    }
};
```

#### å®æ—¶æ€§èƒ½ä»ªè¡¨æ¿

```javascript
// å®æ—¶æ€§èƒ½ç›‘æ§ç»„ä»¶
import React, { useState, useEffect } from 'react';

const PerformanceDashboard = () => {
    const [metrics, setMetrics] = useState({
        cpu: 0,
        memory: 0,
        responseTime: 0,
        throughput: 0,
        errorRate: 0
    });
    
    useEffect(() => {
        const ws = new WebSocket('ws://localhost:3001/metrics');
        
        ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            setMetrics(data);
        };
        
        return () => ws.close();
    }, []);
    
    return (
        <div className="performance-dashboard">
            <div className="metric-card">
                <h3>CPUä½¿ç”¨ç‡</h3>
                <div className={`gauge ${metrics.cpu > 80 ? 'critical' : metrics.cpu > 60 ? 'warning' : 'normal'}`}>
                    {metrics.cpu}%
                </div>
            </div>
            
            <div className="metric-card">
                <h3>å†…å­˜ä½¿ç”¨ç‡</h3>
                <div className={`gauge ${metrics.memory > 85 ? 'critical' : metrics.memory > 70 ? 'warning' : 'normal'}`}>
                    {metrics.memory}%
                </div>
            </div>
            
            <div className="metric-card">
                <h3>å¹³å‡å“åº”æ—¶é—´</h3>
                <div className={`metric ${metrics.responseTime > 1000 ? 'critical' : metrics.responseTime > 300 ? 'warning' : 'normal'}`}>
                    {metrics.responseTime}ms
                </div>
            </div>
        </div>
    );
};
```

### è‡ªåŠ¨åŒ–è°ƒä¼˜

```javascript
// è‡ªåŠ¨æ€§èƒ½è°ƒä¼˜è„šæœ¬
class AutoTuner {
    constructor() {
        this.thresholds = {
            cpu: { warning: 70, critical: 85 },
            memory: { warning: 80, critical: 90 },
            responseTime: { warning: 500, critical: 1000 },
            errorRate: { warning: 0.05, critical: 0.1 }
        };
        
        this.tuningActions = {
            scaleUp: this.scaleUp.bind(this),
            scaleDown: this.scaleDown.bind(this),
            optimizeCache: this.optimizeCache.bind(this),
            restartService: this.restartService.bind(this)
        };
    }
    
    async monitorAndTune() {
        const metrics = await this.getCurrentMetrics();
        
        // CPUä½¿ç”¨ç‡è¿‡é«˜
        if (metrics.cpu > this.thresholds.cpu.critical) {
            await this.tuningActions.scaleUp('backend');
        } else if (metrics.cpu > this.thresholds.cpu.warning) {
            console.warn('CPU usage high, monitoring...');
        }
        
        // å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
        if (metrics.memory > this.thresholds.memory.critical) {
            await this.tuningActions.restartService('backend');
            await this.tuningActions.optimizeCache();
        }
        
        // å“åº”æ—¶é—´è¿‡é•¿
        if (metrics.responseTime > this.thresholds.responseTime.critical) {
            await this.tuningActions.scaleUp('backend');
            await this.tuningActions.optimizeDatabase();
        }
        
        // é”™è¯¯ç‡è¿‡é«˜
        if (metrics.errorRate > this.thresholds.errorRate.critical) {
            await this.tuningActions.restartService('backend');
            await this.sendAlert('High error rate detected');
        }
    }
    
    async scaleUp(service) {
        console.log(`Scaling up ${service}...`);
        // å®ç°è‡ªåŠ¨æ‰©å®¹é€»è¾‘
        await this.updateDockerScale(service, '+1');
    }
    
    async optimizeCache() {
        console.log('Optimizing cache...');
        // æ¸…ç†è¿‡æœŸç¼“å­˜
        await this.clearExpiredCache();
        // é¢„çƒ­çƒ­ç‚¹æ•°æ®
        await this.warmupHotCache();
    }
    
    async getCurrentMetrics() {
        // è·å–å½“å‰ç³»ç»ŸæŒ‡æ ‡
        return {
            cpu: await this.getCpuUsage(),
            memory: await this.getMemoryUsage(),
            responseTime: await this.getAverageResponseTime(),
            errorRate: await this.getErrorRate()
        };
    }
}

// å¯åŠ¨è‡ªåŠ¨è°ƒä¼˜
const tuner = new AutoTuner();
setInterval(() => {
    tuner.monitorAndTune();
}, 60000); // æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
```

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv2.1.0  
**æ›´æ–°æ—¶é—´**ï¼š2024å¹´1æœˆ  
**ç»´æŠ¤å›¢é˜Ÿ**ï¼šAiDesignæ€§èƒ½ä¼˜åŒ–å›¢é˜Ÿ

æ€§èƒ½ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œéœ€è¦å®šæœŸç›‘æ§ç³»ç»ŸæŒ‡æ ‡ï¼Œåˆ†ææ€§èƒ½ç“¶é¢ˆï¼Œå¹¶æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´ä¼˜åŒ–ç­–ç•¥ã€‚å»ºè®®å»ºç«‹å®Œå–„çš„æ€§èƒ½ç›‘æ§ä½“ç³»å’Œè‡ªåŠ¨åŒ–è°ƒä¼˜æœºåˆ¶ã€‚